{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb45158",
   "metadata": {},
   "source": [
    "# Chatbot with message summariz\n",
    "Rather than just trimming or filtering messages, we'll show how to use LLMs to produce a running summary of the conversation.\n",
    " \n",
    "This allows us to retain a compressed representation of the full conversation, rather than just removing it with trimming or filtering.\n",
    "\n",
    "We'll incorporate this summarization into a simple Chatbot.  \n",
    "\n",
    "And we'll equip that Chatbot with memory, supporting long-running conversations without incurring high token cost / latency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad32235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "LLM = ChatGroq(model=\"deepseek-r1-distill-llama-70b\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead67a23",
   "metadata": {},
   "source": [
    "We'll use `MessagesState`, as before.\n",
    "\n",
    "In addition to the built-in `messages` key, we'll now include a custom key (`summary`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac104c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "class State(MessagesState):\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d0df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    response = LLM.invoke(messages)\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b6c00",
   "metadata": {},
   "source": [
    "We'll define a node to produce a summary.\n",
    "\n",
    "Note, here we'll use `RemoveMessage` to filter our state after we've produced the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b8f2421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = LLM.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7062d94",
   "metadata": {},
   "source": [
    "We'll add a conditional edge to determine whether to produce a summary based on the conversation length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "facb9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0b601",
   "metadata": {},
   "source": [
    "## Adding memory\n",
    "\n",
    "Recall that [state is transient](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220) to a single graph execution.\n",
    "\n",
    "This limits our ability to have multi-turn conversations with interruptions. \n",
    " \n",
    "LangGraph can use a checkpointer to automatically save the graph state after each step.\n",
    "\n",
    "This built-in persistence layer gives us memory, allowing LangGraph to pick up from the last state update. \n",
    "\n",
    "As we previously showed, one of the easiest to work with is `MemorySaver`, an in-memory key-value store for Graph state.\n",
    "\n",
    "All we need to do is compile the graph with a checkpointer, and our graph has memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baab772e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(\"summarize_conversation\",summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe6fab9",
   "metadata": {},
   "source": [
    "## Threads\n",
    "\n",
    "The checkpointer saves the state at each step as a checkpoint.\n",
    "\n",
    "These saved checkpoints can be grouped into a `thread` of conversation.\n",
    "\n",
    "Think about Slack as an analog: different channels carry different conversations.\n",
    "\n",
    "Threads are like Slack channels, capturing grouped collections of state (e.g., conversation).\n",
    "\n",
    "Below, we use `configurable` to set a thread ID.\n",
    "\n",
    "![state.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbadf3b379c2ee621adfd1_chatbot-summarization1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "363d5a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hi Lance! ðŸ‘‹ How can I assist you today?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "\n",
      "You told me your name is Lance! ðŸ˜Š\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Alright, the user just said, \"I like the 49ers!\" So first, I need to recognize that they're talking about the San Francisco 49ers, the NFL team.\n",
      "\n",
      "They might be a fan looking for some conversation about the team. I should express enthusiasm to keep the chat positive.\n",
      "\n",
      "I should mention the team's rich history, maybe the 80s and 90s Super Bowl wins, to show I know their background.\n",
      "\n",
      "Also, asking about their favorite player or moment can make the conversation more engaging and personal for them.\n",
      "\n",
      "Keeping it friendly and open-ended will encourage them to share more if they want to.\n",
      "</think>\n",
      "\n",
      "That's awesome! The San Francisco 49ers have such a rich history in the NFL. Are you a lifelong fan, or is there a particular player or moment that got you hooked?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"what's my name?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"i like the 49ers!\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcee8cf",
   "metadata": {},
   "source": [
    "Now, we don't yet have a summary of the state because we still have < = 6 messages.\n",
    "\n",
    "This was set in `should_continue`. \n",
    "\n",
    "```\n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "```\n",
    "\n",
    "We can pick up the conversation because we have the thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c930b786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b77b5ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, so I like Nick Bosa and I heard he's the highest-paid defensive player. I want to find out if that's true. First, I need to figure out how to determine the highest-paid defensive players in the NFL. I know that player contracts can be complicated because they include signing bonuses, guaranteed money, and annual salaries. So, I should look at the average annual salary or the total contract value.\n",
      "\n",
      "I remember that in the NFL, quarterbacks often get the highest contracts, but defensive players can also get paid a lot. Nick Bosa is a defensive end for the San Francisco 49ers, and he's really good, so he probably makes a lot. I think he recently signed a contract extension, maybe in 2023.\n",
      "\n",
      "I should check some sources like ESPN or NFL.com for the latest contract details. Alternatively, I could look up a list of the highest-paid defensive players. I might find that other players like Aaron Donald or J.J. Watt have big contracts, but maybe Bosa's is the biggest now.\n",
      "\n",
      "Wait, I think T.J. Watt of the Pittsburgh Steelers signed a big deal a couple of years ago. His contract was around $28 million annually. But Bosa is younger and has been performing exceptionally well, so maybe he surpassed that.\n",
      "\n",
      "I also remember hearing about the \"highest-paid\" in terms of total guaranteed money. Some contracts have a lot guaranteed, which might make Bosa the highest in that category. Or it could be the average per year. I need to clarify whether it's total contract value or average annual salary.\n",
      "\n",
      "Another angle is to consider the position. Defensive ends often get paid more than other defensive positions. So, among defensive ends, Bosa might be at the top. But compared to all defensive players, maybe someone else is higher.\n",
      "\n",
      "I should also think about when the contracts were signed. The NFL market keeps escalating, so a contract from a few years ago might not be the highest anymore. If Bosa signed his extension recently, it's more likely to be the largest.\n",
      "\n",
      "Looking up, I find that Nick Bosa signed a 5-year, $170 million extension with the 49ers in 2023. That averages to $34 million per year. That seems really high. Comparing that to other defensive players, like Aaron Donald's contract, which was around $31 million annually, Bosa might indeed be the highest-paid now.\n",
      "\n",
      "So, putting it all together, it looks like Nick Bosa is currently the highest-paid defensive player in the NFL based on his recent contract extension.\n",
      "</think>\n",
      "\n",
      "Nick Bosa is indeed considered the highest-paid defensive player in the NFL as of his contract extension in 2023. His 5-year, $170 million deal with the San Francisco 49ers averages $34 million annually, surpassing other top defensive players like Aaron Donald. This makes him the highest-paid defensive player based on average annual salary.\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"i like Nick Bosa, isn't he the highest paid defensive player?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b716d399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
